{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "900c08e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c12b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT PUSH CREDENTIALS TO REPO\n",
    "s3 = boto3.client(\n",
    "    service_name='s3',\n",
    "    region_name='us-west-2',\n",
    "    aws_access_key_id='',\n",
    "    aws_secret_access_key=''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa40ed06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "Successful S3 get_object response. Status - 200\n",
      "   Unnamed: 0           author  \\\n",
      "0     2099088  UghImRegistered   \n",
      "1     2893884  PossibleLesbian   \n",
      "2     2237635        [deleted]   \n",
      "3      498777          Naztash   \n",
      "4     1337130        BurChaBow   \n",
      "\n",
      "                                                body  \\\n",
      "0  &gt; â€œI have friends with the same degree as m...   \n",
      "1  Just a bit of background: I grew up Catholic. ...   \n",
      "2  I myself enjoy approaching an attractive young...   \n",
      "3  You do realize that the contract probably has ...   \n",
      "4  [](/dashiewilliamisboredofnamingemotes)\\n\\nI g...   \n",
      "\n",
      "                                      normalizedBody       subreddit  \\\n",
      "0  > â€œI have friends with the same degree as me, ...        politics   \n",
      "1  Just a bit of background: I grew up Catholic. ...  actuallesbians   \n",
      "2  I myself enjoy approaching an attractive young...       AskReddit   \n",
      "3  You do realize that the contract probably has ...         TopGear   \n",
      "4  \\n I got a teacher that used the most ridiculo...       MLPLounge   \n",
      "\n",
      "  subreddit_id         id                                            content  \\\n",
      "0     t5_2cneq    c1v1gu3  I have friends with the same degree as me, fro...   \n",
      "1     t5_2rch0  t3_185lqh  Just a bit of background: I grew up Catholic. ...   \n",
      "2     t5_2qh1i   t3_g0rk6  I myself enjoy approaching an attractive young...   \n",
      "3     t5_2r9n6    cpcdljw  You do realize that the contract probably has ...   \n",
      "4     t5_2t403    cgej4pd  I got a teacher that used the most ridiculous ...   \n",
      "\n",
      "                                             summary  \n",
      "0                                   co-op, get some.  \n",
      "1  Former Catholic confused about sexuality. Has ...  \n",
      "2  I've noticed a lot of stuff on Reddit concerni...  \n",
      "3  He is not their child, but he is acting like a...  \n",
      "4  Teacher likes papers, and said  \"Pdf isn't the...  \n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "response = s3.get_object(Bucket='reddit-title-generation', Key=\"dataset-train.csv\")\n",
    "\n",
    "status = response.get(\"ResponseMetadata\", {}).get(\"HTTPStatusCode\")\n",
    "\n",
    "if status == 200:\n",
    "    print(f\"Successful S3 get_object response. Status - {status}\")\n",
    "    train = pd.read_csv(response.get(\"Body\"))\n",
    "    print(train.head())\n",
    "else:\n",
    "    print(f\"Unsuccessful S3 get_object response. Status - {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66b6b98c-2615-49e7-ab0f-902edcbaa0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = s3.select_object_content(\n",
    "    Bucket='reddit-title-generation',\n",
    "    Key='dataset-train.csv',\n",
    "    ExpressionType='SQL',\n",
    "    Expression=\"SELECT * FROM s3object S3Object LIMIT 1000\",\n",
    "    InputSerialization = {'CSV': {\"FileHeaderInfo\": \"None\", 'AllowQuotedRecordDelimiter':True}, 'CompressionType': 'NONE'},\n",
    "    OutputSerialization = {'CSV': {}},\n",
    ")\n",
    "\n",
    "records = []\n",
    "for event in resp['Payload']:\n",
    "    if 'Records' in event:\n",
    "        # records.append(event['Records']['Payload'].decode('utf-8'))\n",
    "        records.append(event['Records']['Payload'])  \n",
    "        \n",
    "file_str = ''.join(req.decode('utf-8') for req in records)\n",
    "    # elif 'Stats' in event:\n",
    "    #     statsDetails = event['Stats']['Details']\n",
    "    #     print(\"Stats details bytesScanned: \")\n",
    "    #     print(statsDetails['BytesScanned'])\n",
    "    #     print(\"Stats details bytesProcessed: \")\n",
    "    #     print(statsDetails['BytesProcessed'])\n",
    "    #     print(\"Stats details bytesReturned: \")\n",
    "    #     print(statsDetails['BytesReturned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ecc7521-9b89-41d9-9bd4-6b708e0477dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>normalizedBody</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2099088</td>\n",
       "      <td>UghImRegistered</td>\n",
       "      <td>&amp;gt; â€œI have friends with the same degree as m...</td>\n",
       "      <td>&gt; â€œI have friends with the same degree as me, ...</td>\n",
       "      <td>politics</td>\n",
       "      <td>t5_2cneq</td>\n",
       "      <td>c1v1gu3</td>\n",
       "      <td>I have friends with the same degree as me, fro...</td>\n",
       "      <td>co-op, get some.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2893884</td>\n",
       "      <td>PossibleLesbian</td>\n",
       "      <td>Just a bit of background: I grew up Catholic. ...</td>\n",
       "      <td>Just a bit of background: I grew up Catholic. ...</td>\n",
       "      <td>actuallesbians</td>\n",
       "      <td>t5_2rch0</td>\n",
       "      <td>t3_185lqh</td>\n",
       "      <td>Just a bit of background: I grew up Catholic. ...</td>\n",
       "      <td>Former Catholic confused about sexuality. Has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2237635</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>I myself enjoy approaching an attractive young...</td>\n",
       "      <td>I myself enjoy approaching an attractive young...</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>t3_g0rk6</td>\n",
       "      <td>I myself enjoy approaching an attractive young...</td>\n",
       "      <td>I've noticed a lot of stuff on Reddit concerni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>498777</td>\n",
       "      <td>Naztash</td>\n",
       "      <td>You do realize that the contract probably has ...</td>\n",
       "      <td>You do realize that the contract probably has ...</td>\n",
       "      <td>TopGear</td>\n",
       "      <td>t5_2r9n6</td>\n",
       "      <td>cpcdljw</td>\n",
       "      <td>You do realize that the contract probably has ...</td>\n",
       "      <td>He is not their child, but he is acting like a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1337130</td>\n",
       "      <td>BurChaBow</td>\n",
       "      <td>[](/dashiewilliamisboredofnamingemotes)\\n\\nI g...</td>\n",
       "      <td>ï¿¿ I got a teacher that used the most ridiculou...</td>\n",
       "      <td>MLPLounge</td>\n",
       "      <td>t5_2t403</td>\n",
       "      <td>cgej4pd</td>\n",
       "      <td>I got a teacher that used the most ridiculous ...</td>\n",
       "      <td>Teacher likes papers, and said  \"Pdf isn't the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>443715</td>\n",
       "      <td>bethechangeyouwant</td>\n",
       "      <td>I've been discussing an idea at length in whic...</td>\n",
       "      <td>I've been discussing an idea at length in whic...</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>t5_2sokd</td>\n",
       "      <td>crf8qbu</td>\n",
       "      <td>I've been discussing an idea at length in whic...</td>\n",
       "      <td>All things exist in a constant \"now\", always h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>1711484</td>\n",
       "      <td>freedod</td>\n",
       "      <td>I don't see why people do this shit for fun. L...</td>\n",
       "      <td>I don't see why people do this shit for fun. L...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>t5_2rfxx</td>\n",
       "      <td>cedo4hq</td>\n",
       "      <td>I don't see why people do this shit for fun. L...</td>\n",
       "      <td>if you're going to fuck with people, at least ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>375071</td>\n",
       "      <td>mbitr</td>\n",
       "      <td>These people are giving you solid advice. If y...</td>\n",
       "      <td>These people are giving you solid advice. If y...</td>\n",
       "      <td>army</td>\n",
       "      <td>t5_2qtr8</td>\n",
       "      <td>cgsgfgd</td>\n",
       "      <td>These people are giving you solid advice. If y...</td>\n",
       "      <td>You're headed down the wrong path and have unr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>2254985</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>I did mushrooms about a year ago when I was ba...</td>\n",
       "      <td>I did mushrooms about a year ago when I was ba...</td>\n",
       "      <td>Drugs</td>\n",
       "      <td>t5_2qh7l</td>\n",
       "      <td>t3_riaux</td>\n",
       "      <td>I did mushrooms about a year ago when I was ba...</td>\n",
       "      <td>Had one bad trip, will it affect any future tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>211696</td>\n",
       "      <td>DasGanon</td>\n",
       "      <td>The problem is theory, and manufacture.... let...</td>\n",
       "      <td>The problem is theory, and manufacture.... let...</td>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>t5_2s7tt</td>\n",
       "      <td>cf2omu4</td>\n",
       "      <td>The problem is theory, and manufacture.... let...</td>\n",
       "      <td>It's not the 4 wheel drive that's throwing peo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1028 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0              author  \\\n",
       "0       2099088     UghImRegistered   \n",
       "1       2893884     PossibleLesbian   \n",
       "2       2237635           [deleted]   \n",
       "3        498777             Naztash   \n",
       "4       1337130           BurChaBow   \n",
       "...         ...                 ...   \n",
       "1023     443715  bethechangeyouwant   \n",
       "1024    1711484             freedod   \n",
       "1025     375071               mbitr   \n",
       "1026    2254985           [deleted]   \n",
       "1027     211696            DasGanon   \n",
       "\n",
       "                                                   body  \\\n",
       "0     &gt; â€œI have friends with the same degree as m...   \n",
       "1     Just a bit of background: I grew up Catholic. ...   \n",
       "2     I myself enjoy approaching an attractive young...   \n",
       "3     You do realize that the contract probably has ...   \n",
       "4     [](/dashiewilliamisboredofnamingemotes)\\n\\nI g...   \n",
       "...                                                 ...   \n",
       "1023  I've been discussing an idea at length in whic...   \n",
       "1024  I don't see why people do this shit for fun. L...   \n",
       "1025  These people are giving you solid advice. If y...   \n",
       "1026  I did mushrooms about a year ago when I was ba...   \n",
       "1027  The problem is theory, and manufacture.... let...   \n",
       "\n",
       "                                         normalizedBody          subreddit  \\\n",
       "0     > â€œI have friends with the same degree as me, ...           politics   \n",
       "1     Just a bit of background: I grew up Catholic. ...     actuallesbians   \n",
       "2     I myself enjoy approaching an attractive young...          AskReddit   \n",
       "3     You do realize that the contract probably has ...            TopGear   \n",
       "4     ï¿¿ I got a teacher that used the most ridiculou...          MLPLounge   \n",
       "...                                                 ...                ...   \n",
       "1023  I've been discussing an idea at length in whic...  explainlikeimfive   \n",
       "1024  I don't see why people do this shit for fun. L...    leagueoflegends   \n",
       "1025  These people are giving you solid advice. If y...               army   \n",
       "1026  I did mushrooms about a year ago when I was ba...              Drugs   \n",
       "1027  The problem is theory, and manufacture.... let...      AdviceAnimals   \n",
       "\n",
       "     subreddit_id         id  \\\n",
       "0        t5_2cneq    c1v1gu3   \n",
       "1        t5_2rch0  t3_185lqh   \n",
       "2        t5_2qh1i   t3_g0rk6   \n",
       "3        t5_2r9n6    cpcdljw   \n",
       "4        t5_2t403    cgej4pd   \n",
       "...           ...        ...   \n",
       "1023     t5_2sokd    crf8qbu   \n",
       "1024     t5_2rfxx    cedo4hq   \n",
       "1025     t5_2qtr8    cgsgfgd   \n",
       "1026     t5_2qh7l   t3_riaux   \n",
       "1027     t5_2s7tt    cf2omu4   \n",
       "\n",
       "                                                content  \\\n",
       "0     I have friends with the same degree as me, fro...   \n",
       "1     Just a bit of background: I grew up Catholic. ...   \n",
       "2     I myself enjoy approaching an attractive young...   \n",
       "3     You do realize that the contract probably has ...   \n",
       "4     I got a teacher that used the most ridiculous ...   \n",
       "...                                                 ...   \n",
       "1023  I've been discussing an idea at length in whic...   \n",
       "1024  I don't see why people do this shit for fun. L...   \n",
       "1025  These people are giving you solid advice. If y...   \n",
       "1026  I did mushrooms about a year ago when I was ba...   \n",
       "1027  The problem is theory, and manufacture.... let...   \n",
       "\n",
       "                                                summary  \n",
       "0                                      co-op, get some.  \n",
       "1     Former Catholic confused about sexuality. Has ...  \n",
       "2     I've noticed a lot of stuff on Reddit concerni...  \n",
       "3     He is not their child, but he is acting like a...  \n",
       "4     Teacher likes papers, and said  \"Pdf isn't the...  \n",
       "...                                                 ...  \n",
       "1023  All things exist in a constant \"now\", always h...  \n",
       "1024  if you're going to fuck with people, at least ...  \n",
       "1025  You're headed down the wrong path and have unr...  \n",
       "1026  Had one bad trip, will it affect any future tr...  \n",
       "1027  It's not the 4 wheel drive that's throwing peo...  \n",
       "\n",
       "[1028 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "train = pd.read_csv(StringIO(file_str), header=0)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14a292cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow -q\n",
    "!pip install transformers -q\n",
    "!pip install ohmeow-blurr -q\n",
    "!pip install bert-score -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711cd8d2",
   "metadata": {},
   "source": [
    "## BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7358264d-72d1-4a76-93f7-3b4babc2fbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ikim1\\anaconda3\\lib\\site-packages\\torchaudio\\backend\\utils.py:62: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n",
      "C:\\Users\\ikim1\\anaconda3\\lib\\site-packages\\blurr\\text\\modeling\\question_answering.py:31: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  squad_metric = load_metric(\"squad\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5350122745f24404a3fee7de4cd331fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3af8f8af534506bf3cee34317117a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.text.all import *\n",
    "from transformers import *\n",
    "from blurr.text.data.all import *\n",
    "from blurr.text.modeling.all import *\n",
    "\n",
    "#Select part of data we want to keep\n",
    "train_texts = train[['content','summary']]\n",
    "\n",
    "#Clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc0c6fdb-b2a4-4bbc-9aea-d0e2aae185be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ikim1\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3542: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ikim1\\anaconda3\\lib\\site-packages\\blurr\\text\\data\\seq2seq\\summarization.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final_df = final_df.append(self._process_df_batch(batch_df))\n",
      "C:\\Users\\ikim1\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3542: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ikim1\\anaconda3\\lib\\site-packages\\blurr\\text\\data\\seq2seq\\summarization.py:64: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final_df = final_df.append(self._process_df_batch(batch_df))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ikim1\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3542: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, \n",
    "                                                                  model_cls=BartForConditionalGeneration)\n",
    "\n",
    "# Create mini-batch and define parameters\n",
    "hf_batch_tfm = Seq2SeqBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, \n",
    "    task='summarization')\n",
    "\n",
    "# Simple preprocessing\n",
    "preprocessor = SummarizationPreprocessor(\n",
    "    hf_tokenizer,\n",
    "    text_attr='content',\n",
    "    target_text_attr='summary',\n",
    "    max_input_tok_length=256,\n",
    "    max_target_tok_length=130,\n",
    "    min_summary_char_length=30,\n",
    ")\n",
    "\n",
    "preprocessed_train = preprocessor.process_df(train_texts)\n",
    "\n",
    "\n",
    "# Prepare data for training\n",
    "blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=hf_batch_tfm), noop)\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader('content'), get_y=ColReader('summary'), splitter=RandomSplitter())\n",
    "dls = dblock.dataloaders(preprocessed_train, bs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c5f4f06-9e5c-4885-94a0-8d6ffefe210d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6c3e21ab6447439d03ce3ca5827763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05537b9516b141f89aee82d16016d588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ikim1\\anaconda3\\lib\\site-packages\\torch\\amp\\autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "C:\\Users\\ikim1\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.342315</td>\n",
       "      <td>3.172942</td>\n",
       "      <td>0.202566</td>\n",
       "      <td>0.047688</td>\n",
       "      <td>0.139865</td>\n",
       "      <td>0.653562</td>\n",
       "      <td>0.695616</td>\n",
       "      <td>0.673121</td>\n",
       "      <td>2:57:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.924973</td>\n",
       "      <td>3.115966</td>\n",
       "      <td>0.209516</td>\n",
       "      <td>0.053569</td>\n",
       "      <td>0.148705</td>\n",
       "      <td>0.654510</td>\n",
       "      <td>0.695004</td>\n",
       "      <td>0.673398</td>\n",
       "      <td>2:21:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.240080</td>\n",
       "      <td>3.207419</td>\n",
       "      <td>0.211030</td>\n",
       "      <td>0.053737</td>\n",
       "      <td>0.148333</td>\n",
       "      <td>0.655003</td>\n",
       "      <td>0.697316</td>\n",
       "      <td>0.674661</td>\n",
       "      <td>2:36:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ikim1\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3542: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ikim1\\anaconda3\\lib\\site-packages\\transformers\\generation_utils.py:1227: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 142 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f262e5791404cde877bef8ae6a52681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55a1e133cc248d3a9812daedeb3cabb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b843a1f7e24445589a4a545263b734fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e0f7ca196d496bb2797b96ae110980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Define performance metrics\n",
    "seq2seq_metrics = {\n",
    "        'rouge': {\n",
    "            'compute_kwargs': { 'rouge_types': [\"rouge1\", \"rouge2\", \"rougeL\"], 'use_stemmer': True },\n",
    "            'returns': [\"rouge1\", \"rouge2\", \"rougeL\"]\n",
    "        },\n",
    "        'bertscore': {\n",
    "            'compute_kwargs': { 'lang': 'fr' },\n",
    "            'returns': [\"precision\", \"recall\", \"f1\"]}}\n",
    "\n",
    "#Model\n",
    "model = BaseModelWrapper(hf_model)\n",
    "learn_cbs = [BaseModelCallback]\n",
    "fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "#Specify training\n",
    "learn = Learner(dls, model,\n",
    "                opt_func=ranger,loss_func=CrossEntropyLossFlat(),\n",
    "                cbs=learn_cbs,splitter=partial(blurr_seq2seq_splitter, arch=hf_arch)).to_fp16()\n",
    "\n",
    "#Create optimizer with default hyper-parameters\n",
    "learn.create_opt() \n",
    "learn.freeze()\n",
    "\n",
    "#Training\n",
    "learn.fit_one_cycle(3, lr_max=3e-5, cbs=fit_cbs)\n",
    "\n",
    "#Exporting model\n",
    "learn.save('reddit_summary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23a98ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/reddit_summary.pkl.pth')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exporting model\n",
    "learn.save('reddit_summary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3de6403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Loading model\n",
    "# learn.load('reddit_summary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "479dee21-f75c-454b-a52e-65b4b0b0f31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prediction 1 ===\n",
      "{'generated_texts': \" co-op programs can make you more marketable, not less marketable.  It's not just about luck, it's about networking, experience and professionalism.  If you want to get out of your rut,\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = learn.blurr_generate(train_texts.iloc[0].content, early_stopping=False, num_return_sequences=1, \\\n",
    "                               min_length=30, max_length=50)\n",
    "\n",
    "for idx, o in enumerate(outputs):\n",
    "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63aed238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I have friends with the same degree as me, from a worse school, but because of who they knew or when they happened to graduate, theyâ€™re in much better jobs,â€ said Kyle Bishop, 23, a 2009 graduate of the University of Pittsburgh who has spent the last two years waiting tables, delivering beer, working at a bookstore and entering data. â€œItâ€™s more about luck than anything else.â€ \\n It's not  just  about luck, Kyle.  It's also about networking, experience and professionalism. \\n This is why you should, if you have the opportunity, enrol in a co-op program.  I graduated with 2 full years of real-world work experience in my field and had a job lined up before I graduated.  In fact, I still don't technically have my degree because I was a lazy student and had to take some part time courses while I worked full time.  But that hasn't stopped me from already being hired for two jobs that pay 65k+ during the tail end of a recession.  At the end of the day they hire me because I can prove my effectiveness as an employee, not just as a student. \\n Granted my experience comes from an in-demand field.  But when I compare myself to others who have taken more schooling in the same field but without coop, I'm WAY more marketable.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts.iloc[0].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dd5d95",
   "metadata": {},
   "source": [
    "## T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1beed3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d96ce8d16ed49cf824133315d008227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b38e2a65b9341f0bf52c956eaa9718b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89232da966554b1da2913e3928296e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c7d0d84447428b8020aa520f9600a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ikim1\\anaconda3\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "t5_summarizer = pipeline(\"summarization\", model=\"t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "000dfa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'coop programs are a great way to gain real-world work experience . Kyle bishop, 23, graduated from the university of Pittsburgh with 2 years of work experience in his field . he has been hired for two jobs that pay 65k+ during the tail end of a recession .'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_summarizer(train.content[0], min_length=5, max_length=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
