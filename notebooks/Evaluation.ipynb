{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yao\\Anaconda3\\lib\\site-packages\\blurr\\text\\modeling\\question_answering.py:31: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  squad_metric = load_metric(\"squad\")\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Yao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Yao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Yao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Yao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from fastai.text.all import *\n",
    "from fastai import *\n",
    "from blurr import *\n",
    "#from transformers import *\n",
    "import transformers\n",
    "from blurr.text.data.all import *\n",
    "from blurr.text.modeling.all import *\n",
    "import bert_score\n",
    "from bert_score import score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import io\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from fastbook import load_learner\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##!pip install fastbook\n",
    "##!pip install fastai\n",
    "#!pip install transformers\n",
    "##!pip install blurr\n",
    "#!pip install --upgrade h5py\n",
    "#!pip install libhdf5\n",
    "#print(h5py.__version__)\n",
    "#!pip install bert_score\n",
    "#!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers -Uqq\n",
    "#!pip install datasets -Uqq\n",
    "#!pip install bert-score -Uqq\n",
    "#!pip install sacremoses \n",
    "#!pip install ohmeow-blurr -Uqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('dataset-test.csv') # use test file just to load faster\n",
    "#df_test = df_test[df_test['subreddit'] == 'leagueoflegends'] #subset\n",
    "test_texts = df_test[['content','summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = pd.read_csv('dataset-train.csv')\n",
    "#train_texts = df_train[['content','summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(data):\n",
    "    stop_words = set(stopwords.words('english')) #use stop words\n",
    "    #data = re.sub('(\\d+)', '', data) #remove digits\n",
    "    data = re.sub('\\W+',' ', data) #remove special chaacters\n",
    "    word_tokens = word_tokenize(data.lower()) #tokenize the string\n",
    "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words] #remove stop words\n",
    "    #porter_stemmer = PorterStemmer() #stem the words \n",
    "    #stemmed_words = [porter_stemmer.stem(word) for word in filtered_sentence]\n",
    "    wordnet_lemmatizer = WordNetLemmatizer() #lemm the word, does better than stem the word\n",
    "    lemm_words = [wordnet_lemmatizer.lemmatize(word) for word in filtered_sentence]\n",
    "    return ' '.join(lemm_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_rscore(reference, candidate): #assuming both are lists, Rouge\n",
    "    rscores = []\n",
    "    rscorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    for i in range(len(reference)):\n",
    "        rscore = rscorer.score(reference[i], candidate[i])\n",
    "        rscores.append(list(rscore.values())[0][2]) # fscore\n",
    "    return rscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_bscore(reference, candidate): #assuming both are lists, Bertscore\n",
    "    P, R, F1 = score(candidate, reference, lang=\"en\")\n",
    "    return F1.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yao\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3543: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  \"`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yao\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3543: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  \"`as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your \"\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, \n",
    "                                                                  model_cls=transformers.BartForConditionalGeneration)\n",
    "\n",
    "# Create mini-batch and define parameters\n",
    "hf_batch_tfm = Seq2SeqBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, \n",
    "    task='summarization')\n",
    "\n",
    "# Simple preprocessing\n",
    "preprocessor = SummarizationPreprocessor(\n",
    "    hf_tokenizer,\n",
    "    text_attr='content',\n",
    "    target_text_attr='summary',\n",
    "    max_input_tok_length=256,\n",
    "    max_target_tok_length=130,\n",
    "    min_summary_char_length=30,\n",
    ")\n",
    "\n",
    "preprocessed_train = preprocessor.process_df(test_texts) #test_texts here\n",
    "\n",
    "\n",
    "# Prepare data for training\n",
    "blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=hf_batch_tfm), noop)\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader('content'), get_y=ColReader('summary'), splitter=RandomSplitter())\n",
    "# Batch size can be changed here\n",
    "dls = dblock.dataloaders(preprocessed_train, bs = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define performance metrics\n",
    "seq2seq_metrics = {\n",
    "        'rouge': {\n",
    "            'compute_kwargs': { 'rouge_types': [\"rouge1\", \"rouge2\", \"rougeL\"], 'use_stemmer': True },\n",
    "            'returns': [\"rouge1\", \"rouge2\", \"rougeL\"]\n",
    "        },\n",
    "        'bertscore': {\n",
    "            'compute_kwargs': { 'lang': 'fr' },\n",
    "            'returns': [\"precision\", \"recall\", \"f1\"]}}\n",
    "\n",
    "#Model\n",
    "model = BaseModelWrapper(hf_model)\n",
    "learn_cbs = [BaseModelCallback]\n",
    "fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "#Specify training\n",
    "learn = Learner(dls, model,\n",
    "                opt_func=ranger,loss_func=CrossEntropyLossFlat(),\n",
    "                cbs=learn_cbs,splitter=partial(blurr_seq2seq_splitter, arch=hf_arch)).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('models/reddit_summary.pkl.pth')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save('reddit_summary.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = learn.load('bart_reddit_summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inf_learn = load_learner('models/bart_reddit_summary.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prediction 1 ===\n",
      "{'generated_texts': 'Racism is, in a weird way, an even touchier topic than rape, even though a single racist act may be less harmful than any sexual assault. There are seething undercurrents of unaddressed issues when'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = learn.blurr_generate(test_texts.iloc[0].content, early_stopping=False, num_return_sequences=1, \\\n",
    "                               min_length=30, max_length=50)\n",
    "for idx, o in enumerate(outputs):\n",
    "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$prediction$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('dataset-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = df_test[df_test['subreddit'] == 'AskReddit'].sample(50)[['content','summary']]\n",
    "df_l = df_test[df_test['subreddit'] == 'leagueoflegends'].sample(50)[['content','summary']]\n",
    "df_t = df_test[df_test['subreddit'] == 'tifu'].sample(50)[['content','summary']]\n",
    "df_r = df_test[df_test['subreddit'] == 'relationships'].sample(50)[['content','summary']]\n",
    "df_ra = df_test[df_test['subreddit'] == 'relationship_advice'].sample(50)[['content','summary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing optional\n",
    "df_a['content'] = list(map(pre_processing, df_a['content'])) \n",
    "df_a['summary'] = list(map(pre_processing, df_a['summary'])) \n",
    "df_l['content'] = list(map(pre_processing, df_l['content'])) \n",
    "df_l['summary'] = list(map(pre_processing, df_l['summary'])) \n",
    "df_t['content'] = list(map(pre_processing, df_t['content'])) \n",
    "df_t['summary'] = list(map(pre_processing, df_t['summary'])) \n",
    "df_r['content'] = list(map(pre_processing, df_r['content'])) \n",
    "df_r['summary'] = list(map(pre_processing, df_r['summary'])) \n",
    "df_ra['content'] = list(map(pre_processing, df_ra['content'])) \n",
    "df_ra['summary'] = list(map(pre_processing, df_ra['summary'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Putting an astronaut into orbit is expensive (currently about $65 million) so the space agency that bought the ticket obviously wants to get its money's worth out of their employee. \\n Most astronaut work is maintaining science projects onboard the station. Some astronauts are trained in EVA maintenance and repair, so they have to do things like fix broken ammonia coolant pumps (like we saw last week) or service pallets of exposed materials outside the station, or inspect areas of the ISS that can't be viewed from the onboard cameras. \\n The International Space Station is fueled by money, so most days, the astronauts conduct press conferences with Earthbound reporters. The public relations aspect is critical for maintaining support for spending tax dollars, so it's why astronauts talk to the assorted Hot 96s and Kiss 105s and The Q-101s around the country - - taxpayers need to remember there are people up there in space. \\n In order to reduce osteoporosis and muscle atrophy, astronauts spend almost three hours each day exercising. It seems like a lot of time, but imagine how much exercise their muscles don't get from simply walking around or even sitting up straight in a chair. Heart rates during sleep average about 30 beats per minute, so with the heart being a muscle that can atrophy, it's critical that long periods of exercise need to happen every single day.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a.iloc[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(test_texts):\n",
    "    #list(outputs[0].values())\n",
    "    predictions = []\n",
    "    for i in range(len(test_texts)):\n",
    "        outputs = learn.blurr_generate(test_texts.iloc[i].content, early_stopping=False, num_return_sequences=1, \\\n",
    "                                   min_length=30, max_length=50)\n",
    "        predictions.append(list(outputs[0].values())[0])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_p = make_predictions(df_a)\n",
    "l_p = make_predictions(df_l)\n",
    "t_p = make_predictions(df_t)\n",
    "r_p = make_predictions(df_r)\n",
    "ra_p = make_predictions(df_ra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_rouge(test_texts, predictions):\n",
    "    score_list = f_rscore(list(test_texts.summary), predictions)\n",
    "    return np.average(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_bertscore(test_texts, predictions):\n",
    "    score_list = f_bscore(list(test_texts.summary), predictions)\n",
    "    return np.average(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1409546271588405"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rouge(df_a, a_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1390674058598556"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rouge(df_l, l_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14295083612270246"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rouge(df_t, t_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15826219750022819"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rouge(df_r, r_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16458580163167766"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rouge(df_ra, ra_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8587509858608245"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_bertscore(df_a, a_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8485599493980408"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_bertscore(df_l, l_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8507759821414947"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_bertscore(df_t, t_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8596891975402832"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_bertscore(df_r, r_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8590439307689667"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_bertscore(df_ra, ra_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0.038461538461538464),\n",
       " (10, 0.0),\n",
       " (23, 0.049999999999999996),\n",
       " (27, 0.046511627906976744)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list = f_rscore(list(df_t.summary), t_p)\n",
    "[(i ,e) for i, e in enumerate(score_list) if e < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.21875),\n",
       " (1, 0.2903225806451613),\n",
       " (2, 0.339622641509434),\n",
       " (11, 0.2153846153846154),\n",
       " (21, 0.24324324324324323),\n",
       " (25, 0.2318840579710145),\n",
       " (26, 0.24000000000000005),\n",
       " (28, 0.3013698630136986),\n",
       " (33, 0.25396825396825395),\n",
       " (40, 0.24615384615384614),\n",
       " (42, 0.22641509433962265)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list = f_rscore(list(df_t.summary), t_p)\n",
    "[(i ,e) for i, e in enumerate(score_list) if e >0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Example$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This happened today around 12am. \\n I had just left my girlfriend\\'s house and we said our goodbyes, then entered my car. I\\'m just thinking what a great time it would be to have a cigarette, but I wait a bit before I light it, so I start the car and all of a sudden a SPIDER the size of megalodon crawls onto my front windshield, so my first reaction is to freeze and assess the situation; is it inside or outside? I am extremely afraid of spiders so you can imagine what it\\'d be like. After waiting for confirmation that it\\'s outside, I used the wipers to push it off and it runs for it\\'s dear life. I\\'m thinking \"haha, gotcha\", then it\\'s gone. No sign of monster spider. I roll my windows down and light my cigarette when all of a sudden, it\\'s back. The spider crawls back onto the front windshield, just sitting there. I continuously shit myself and regret getting into my car, I close the windows and at the same time I panic because the cigarette smell will definitely stain more without the windows open, but I don\\'t want to open the window in case Goliath tries to crawl in. I puff on the cigarette continuously to relax myself while the spider crawls around my car. I start driving in an attempt to push the spider off with the wind, and after about 5 minutes or so I assume it should be gone by now and roll my windows back down. Suddenly I see a black object crawling near my stereo/dashboard area and I flinch so fucking hard my asshole closed up and my brain froze, I swerve in the middle of the road from the reaction. I close my windows back up and at this moment I realised I had almost hit a parked car because I was so concentrated on handling the cigarette, dodging the spider and closing the window, so I pull over to parking on the side of the road and waited until the spider was gone. \\n Just sitting there, windows closed, cigarette smoke going everywhere and my dignity gone. \"It\\'s just a spider.\" I think to myself, but there\\'s no point of trying to convince myself. It\\'s out to murder me. I\\'m sitting there, waiting for the spider to appear when out at the corner of my eye, I see it. It\\'s just sitting there on my passenger side window. We have a staring battle and then it crawls to the top of my roof. I started talking to myself, questioning my sanity \"HOW THE FUCK DID IT NOT COME OFF AT 80KMPH?\"\\nI start the engine again and I wait a bit more. I open the windows a notch to smoke the rest and throw the cigarette out and then I close it while fearing for my life. I start driving and feel tingling on my legs so I look down, forgetting road safety rules and start brushing at my legs dreading the moment I feel the spider crawling on me. I bring up my flashlight to try and find it while trying to get home. I eventually arrive to my comforting parking space at home but I sit there, waiting for the spider to appear. No signs of it. I was afraid. I figure \"this is my chance\", I grab my bag, open the door and jump out like a maniac as a car passes my house probably thinking \"what the hell is wrong with that guy\" and I slam the door shut, quickly running to my front door and stumbling for my keys rushing to find a mirror to see if the spider is on me. I examine myself and there is no spider to be found. I continued to be paranoid for the rest of the night and left me unable to sleep well. Also, I live in Australia.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.iloc[10].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nature is scary'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.iloc[10].summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A spider the size of a megalodon crawls onto my windshield. I am extremely afraid of spiders so you can imagine what it'd be like to have one crawl on you. I continued to be paranoid for the rest\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_p[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Example$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello TIFU. I knew one day I would have a story thats TIFU worthy. I just didnt expect it to come so early. \\n and this actually is happening today. \\n Im a 22 yo undergrad student, majoring in Mass communication with a emphasis on Public Relations and Advertising. Im pretty well into my degree, past my core classes and actually into the classes that relate to my major. One of the classes is an Advertising analysis and study class. Basically, we learn about what makes a good advertisement, what kind of response we should get, and how to interest an audience im our product. \\n One of the major projects in this class is a short presentation about a couple of advertisements, one good, one bad, what kind of response they provoke and how to make them better. We then have to present them in front of the class, in the form of a short powerpoint. Seems simple enough, right? So, yesterday, I got up and went to a different class, knowing that at some point I would need to review my presentation and prepare. But, being the child that I am, and this being the internet, I got distracted. Badly. Between a mid afternoon nap and spending time with my SO, I didnt start looking at my project until 1am. No worries, Ill just do a quick review, take some notes and bring my notes to class for my presentation. Load up my power point and........oh god please.\\nFor whatever reason I didnt save the right file. Rage builds a little bit, but nothing I cant handle. Ill just redo the powerpoint, and that will count as my review. I stay up redo-ing the stupid thing, but it doesnt nearly as long as the first time around when I created the project because I knew where all the pages and materials I needed where. Finally completed, I save the stupid project to my flash drive at least four times before safely unplugging my flashdrive and setting it next to my wallet and keys so I know where it is in the morning. I look at the clock, and its roughly 3:30 AM. The class starts at 9:00. I like to get atleast 6 hours of sleep. Rage rising. I take a shower and everything else to get ready for the sleepy times. Back to bed and look at my clock again. 4:00 am I sigh softly, knowing tomorrow (today) is going to be rough, but that it wont last forever. Ill do a killer presentation, and then come back home for a celebratory nap. Ha. hahahahahahaha .....nope \\n I woke up today at 9:30. FURIOUS. I think the first thing that came out of my mouth today was FUCK when I realized what had happened. In my haste to get a somewhat good nights rest, I forgot to set my alarm. And missed my presentation day. I think maybe I can make it class, if by some miracle my apartment complexs bus to campus is here. But then I remember that the professor usually lets us out ten minutes early. God. Damn. It. \\n This project is a good chunk of our grade for this class. \\n Any suggestions on what to do now?'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.iloc[1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Burned the mightnight oil a little too hard. Forgot to set my alarm to wake up, missed presentation day for my project. \\n TIFU'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.iloc[1].summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Im a 22-year-old student majoring in Mass communication with a emphasis on Public Relations and Advertising. I got distracted by the internet and forgot to set my alarm for my presentation day, so I missed my presentation.'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_p[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Example$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My best friend teaches freshman english. After class one day, a note was left and a group of girls in the next class grabbed it, read it, and started giggling. My friend grabbed the note from the girls, and threw it away without reading it, trying to save the student (a quite and polite student), and probably herself, some humiliation. However, when the next day rolled around and the same girl left another note behind, it was fair game. The 14-year-old had left behind a note addressed to her boyfriend and it read: \"Hey, wanna come over after school for some sex and capri sun?\". Unsure of what Capri Sun had to do with sex, my friend decided to search for it on urbandictionary.com. \"Capri Sun\" means getting jizzed on the face after a blow job. She was never able to look at that girl the same.'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a.iloc[24].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14-year old freshman wanted her boyfriend to come on her face.'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a.iloc[24].summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Capri Sun\" means getting jizzed on the face after a blow job. The 14-year-old had left behind a note addressed to her boyfriend and it read: \"Hey, wanna come over after school for some'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_p[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Real Example$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Prediction 1 ===\n",
      "{'generated_texts': 'A UC Berkeley student has created an app that generates a title for a userâ€™s post that can accurately summarize the content of a post. The product is still in the early stages of development and would appreciate any feedback.'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "content = [\"Hello David, my name is George and I'm currently a MIDS candidate at UC Berkeley.I'm a big fan of your work and my team of data scientists and developers have created a product I think youâ€™d be interested in. Do you know the hardest part about coming up with an elevator pitch? Itâ€™s trying to condense the most important parts into a concise number of words. That same difficulty can be found on Reddit, one of the fastest growing social media sites in the world. Weâ€™ve analyzed reddit data over a 10-year period and found that nearly 20% of all posts and articles had ineffective or erroneous titles. So, whatâ€™s the solution? Our product is a web-based app that takes a userâ€™s post and generates a title that has been evaluated to accurately summarize the content. We're still in the early stages of development and would appreciate any feedback, would you be interested in meeting with my team to talk more through our product?\"]\n",
    "outputs = learn.blurr_generate(content, early_stopping=False, num_return_sequences=1, \\\n",
    "                               min_length=30, max_length=50)\n",
    "for idx, o in enumerate(outputs):\n",
    "    print(f'=== Prediction {idx+1} ===\\n{o}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$BertScore Example$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.8793852925300598),\n",
       " (1, 0.8709421753883362),\n",
       " (2, 0.8801113963127136),\n",
       " (3, 0.8368353247642517),\n",
       " (4, 0.8676187992095947),\n",
       " (5, 0.8566980361938477),\n",
       " (6, 0.8403998017311096),\n",
       " (7, 0.8571620583534241),\n",
       " (8, 0.8545660972595215),\n",
       " (9, 0.8320644497871399),\n",
       " (10, 0.8259784579277039),\n",
       " (11, 0.879986047744751),\n",
       " (12, 0.8258947134017944),\n",
       " (13, 0.8445872068405151),\n",
       " (14, 0.8670421838760376),\n",
       " (15, 0.8418312668800354),\n",
       " (16, 0.8355985879898071),\n",
       " (17, 0.8534197807312012),\n",
       " (18, 0.847183108329773),\n",
       " (19, 0.7866148948669434),\n",
       " (20, 0.8464949131011963),\n",
       " (21, 0.8735225796699524),\n",
       " (22, 0.8166868686676025),\n",
       " (23, 0.8529530763626099),\n",
       " (24, 0.8596628308296204),\n",
       " (25, 0.8414990305900574),\n",
       " (26, 0.885001540184021),\n",
       " (27, 0.8319551944732666),\n",
       " (28, 0.8730170726776123),\n",
       " (29, 0.8451743125915527),\n",
       " (30, 0.8385426998138428),\n",
       " (31, 0.8534262180328369),\n",
       " (32, 0.8014107942581177),\n",
       " (33, 0.8693335652351379),\n",
       " (34, 0.8324257135391235),\n",
       " (35, 0.8394963145256042),\n",
       " (36, 0.8568946123123169),\n",
       " (37, 0.8460912704467773),\n",
       " (38, 0.8587995171546936),\n",
       " (39, 0.8547101020812988),\n",
       " (40, 0.8913272619247437),\n",
       " (41, 0.8569052815437317),\n",
       " (42, 0.8702713251113892),\n",
       " (43, 0.8632171750068665),\n",
       " (44, 0.8558826446533203),\n",
       " (45, 0.8479358553886414),\n",
       " (46, 0.8358486294746399),\n",
       " (47, 0.8542033433914185),\n",
       " (48, 0.8579145669937134),\n",
       " (49, 0.8442751169204712)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list = f_bscore(list(df_t.summary), t_p)\n",
    "[(i ,e) for i, e in enumerate(score_list) if e < 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
